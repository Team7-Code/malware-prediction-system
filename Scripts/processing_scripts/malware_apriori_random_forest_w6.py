import pandas as pd
import numpy as np
from keras import Sequential
from keras.layers import Conv2D, Flatten, Dense
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import Lasso, Ridge, LogisticRegression
from malware_plots import *

path = 'D:/Document/10 DAAN 881 - Decision Making/Project/data/'
x_train = pd.read_pickle(path + '/x_train_cleaned_for_week5.pkl')
y_train = pd.read_pickle(path + '/y_train_cleaned_for_week5.pkl')

# x_train.info()

rand_int = np.random.randint(0, x_train.shape[0], 250000)
sample_x = pd.DataFrame(x_train.iloc[rand_int])
sample_y = pd.DataFrame(y_train.iloc[rand_int])
# sample_y["HasDetections"].value_counts()
# rand_int = np.random.randint(0, X_train.shape[0], 1000000)
# sample_x = pd.DataFrame(X_train.iloc[rand_int])
# sample_y = pd.DataFrame(Y_train.iloc[rand_int])
#
# rand_int = np.random.randint(0, X_test.shape[0], 100000)
# test_x = pd.DataFrame(X_test.iloc[rand_int])
# test_y = pd.DataFrame(Y_test.iloc[rand_int])

sample_x["HasDetections"] = sample_y["HasDetections"]

cols_to_remove = ["Census_FirmwareVersionIdentifier",
"Census_OEMNameIdentifier",
"Census_OSVersion",
"OsBuildLab",
"Census_FirmwareManufacturerIdentifier",
"AVProductStatesIdentifier",
"Census_ProcessorModelIdentifier",
"PuaMode",
"IsBeta",
"UacLuaenable",
"Census_IsFlightsDisabled",
"Firewall",
"Platform",
"Census_DeviceFamily",
"ProductName",
"AutoSampleOptIn",
"HasTpm",
"Census_InternalPrimaryDisplayResolutionHorizontal",
"Census_InternalPrimaryDisplayResolutionVertical"
]
drop2 = ["Census_ProcessorCoreCount",
"Census_PrimaryDiskTotalCapacity",
"Census_SystemVolumeTotalCapacity",
"Census_TotalPhysicalRAM"]

sample_x.drop(drop2, inplace=True, axis=1)
sample_x.drop(cols_to_remove, inplace=True, axis = 1)
# len(sample_x.columns) # should be equal to 52, 51 categorical cols and 1 detection col
# sample_x.info()

np.random.seed(123)

train_x, train_y, test_x, test_y = train_test_split(sample_x, sample_y, test_size=0.2)

# Apriori Analysis
sample_x.shape
sample_x["HasDetections"].value_counts()
dataset = sample_x[sample_x["HasDetections"]==1]
dataset = dataset.astype('category')
df = pd.get_dummies(dataset, prefix = dataset.columns, prefix_sep="$")
# df["HasDetections$0"].head()
dataset["HasDetections"].value_counts()
df.to_pickle(path+"/df_columns_with dummied_week6_all1.pkl")

df = pd.read_pickle(path+"/df_columns_with dummied_week6.pkl")
df["HasDetections$1"].value_counts()
# Apriori function
x = apriori(df, min_support =0.2, use_colnames=True, max_len=5)
x.info()
x["length"] = x["itemsets"].apply(lambda x: len(x))
x = x.sort_values(by=["length"], ascending=False)

x.to_csv(path + "/assco.csv", index=False)

# x["length"].value_counts()
top_10 = x[x["length"]>=3]
# top_10.info()
# top_10.head()
features_list = []
component_list = []
# count1 = 0
# count2 = 0
count = 0
# for i in x["itemsets"]:
    # if "HasDetections$1" in list(i):
        # count1 = count1+1
    # if "HasDetections$0" in list(i):
        # count2 = count2+1


for i in top_10["itemsets"]:
    if ("HasDetections$1" in list(i)):
        # print(True)
        for j in i:
            if (j!="HasDetections$1"):
                features_list.append('_'.join(j.split("$")[:-1]))
                component_list.append(j)
        count = count + 1

# list(top_10["itemsets"])
# len(set(features_list))
# len(set(component_list))
# set(features_list)

temp = pd.DataFrame(pd.DataFrame(features_list, columns=["Features"])["Features"].value_counts())
temp[temp["Features"]!="HasDetections"]
temp[temp.index != "HasDetections"]
features_list.remove('HasDetections')
component_list.remove("HasDetections$1")

plot_feature(temp[temp.index != "HasDetections"])
temp[temp.index != "HasDetections$1"].to_csv(path + "/component_list_week6.csv")
temp
# boruta implementation
from boruta import BorutaPy

yR = df["HasDetections_1"].values.ravel()
rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)
feat_selector = BorutaPy(rf, n_estimators=200, verbose=2, random_state=1)
X_train_array = df.drop(["HasDetections_1"], inplace=False, axis=1).values
feat_selector.fit(X_train_array, yR)
feature_imp = pd.Series(feat_selector.ranking_,
                        index=sample_x.columns).sort_values(ascending=True)


# Ridge regression
features_for_reg = list(set(component_list))
features_to_select = list(set(features_list))

features_to_select.remove("HasDetections")
features_for_reg.remove("HasDetections$1")
# features_for_reg.remove("HasDetections$0")
# features_to_select
sample_train = sample_x[features_to_select]
sample_train.info()
len(features_to_select)
# sample_train_dumm = df[features_for_reg]
# sample_train_dumm.info()
sample_x.drop(["HasDetections"], inplace=True, axis=1)
selective_dummy = pd.get_dummies(sample_train.astype('category'), prefix_sep="$")

train_x, test_x, train_y, test_y = train_test_split(selective_dummy,
                                                    sample_y, test_size=0.2)


sample_train = sample_train.astype('category')



sample_train = pd.get_dummies(sample_train, prefix=sample_train.columns)

test_x = test_x.astype('category')
test_x = pd.get_dummies(test_x, prefix=test_x.columns)

test_x1 = test_x[features_for_reg].values
test_y = test_y.values


rr = Ridge(alpha=0.1)
X = train_x.values
X.shape
y = train_y.values
y.shape
rr.fit(X, y)
rr.coef_
train_x.shape
len(features_for_reg)



logreg = LogisticRegression()
las = Lasso(alpha=0.1)

las.fit(X,y)
logreg.fit(X, y)
train_x.shape
X.shape
y_pred_l = logreg.predict(train_x)
y_pred_las = las.predict(train_x)

y_pred = rr.predict(train_x)
acc = metrics.accuracy_score(test_y, np.round(y_pred, 0).astype(int))
print(classification_report(test_y, np.round(y_pred, 0).astype(int)))
print("Accuracy: ", metrics.accuracy_score(train_y, np.round(y_pred_l, 0).astype(int)))

y_pred_las[1:10]
plot_roc(test_y, y_pred_las, path+"/week6/roc_sample_250000_lasso_final.png",
         "Lasso Regression ROC plot")
cm = confusion_matrix(test_y.values.ravel(), np.round(y_pred_las,0))
plot_confusion_matrix(cm, classes = ['No Detection', 'Yes Detection'],
                      save_path=path + "/week6/cm_sample_250000_lr_final",
                      title = 'Malware Detection Confusion Matrix')

corr = sample_train.corr()
plt.figure(figsize=(20,20))
sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool),
            cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True)
plt.show()


# random forest

type(train_y)
train_y.shape
rf = RandomForestClassifier(n_estimators=100, verbose=1, bootstrap=True, n_jobs=-1)
rf.fit(X,train_y.values)

feature_imp = pd.Series(rf.feature_importances_,
                        index=X.columns).sort_values(ascending=False)

y_pred, acc = evaluate(rf, test_x, test_y)


plot_roc(test_y, y_pred_las, path+"/week6/roc_sample_250000_RF2_final.png",
         "Lasso Regression ROC plot")
cm = confusion_matrix(test_y.values.ravel(), np.round(y_pred,0))
plot_confusion_matrix(cm, classes = ['No Detection', 'Yes Detection'],
                      save_path=path + "/week6/cm_sample_250000_RF2_final",
                      title = 'Malware Detection Confusion Matrix')