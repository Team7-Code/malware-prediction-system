import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sqlalchemy import create_engine
from scipy import stats
from progressbar import ProgressBar
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
import seaborn as sns
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import confusion_matrix
import itertools
from malware_plots import *

# import pickle
path = 'D:/Document/10 DAAN 881 - Decision Making/Project/data/'
X_train = pd.read_pickle(path + "/x_train_cleaned.pkl")

x_train = X_train[X_train.columns[1:]]
y_train = X_train[X_train.columns[-1]]
x_train.drop('HasDetections', axis = 1, inplace=True)

x_train.to_pickle(path + "/x_train_cleaned.pkl")
y_train = x_train[x_train.columns[-1]]
# y_train.head()
x_train = x_train[x_train.columns[:-1]]

# cleaning Smartscreen column
x_train.SmartScreen = x_train.SmartScreen.replace("Promt", "Prompt")
x_train.SmartScreen = x_train.SmartScreen.replace("prompt", "Prompt")
x_train.SmartScreen = x_train.SmartScreen.replace("warn", "Warn")
x_train.SmartScreen = x_train.SmartScreen.replace("requireAdmin", "RequireAdmin")
x_train.SmartScreen = x_train.SmartScreen.replace("requireadmin", "RequireAdmin")
x_train.SmartScreen = x_train.SmartScreen.replace("OFF", "off")
x_train.SmartScreen = x_train.SmartScreen.replace("on", "On")
x_train.SmartScreen = x_train.SmartScreen.replace("off", "Off")
x_train.SmartScreen = x_train.SmartScreen.replace("ExistsNotSet", "Off")
x_train.SmartScreen = x_train.SmartScreen.replace("0", "Off")
x_train.SmartScreen = x_train.SmartScreen.replace("00000000", "Off")
x_train.SmartScreen = x_train.SmartScreen.replace("Enabled", "On")
x_train.SmartScreen = x_train.SmartScreen.replace("&#x02;", "Off")
x_train.SmartScreen = x_train.SmartScreen.replace("&#x01;", "Off")
x_train.SmartScreen = x_train.SmartScreen.replace("&#x03;", "Off")
x_train.SmartScreen = x_train.SmartScreen.replace("Prompt", "Warn")

x_train.to_pickle(path + "/x_train_cleaned_for_week5.pkl")
y_train.to_pickle(path + "/y_train_cleaned_for_week5.pkl")

#### columns removed based on chi dist

cols_to_remove = ["Census_FirmwareVersionIdentifier",
"Census_OEMNameIdentifier",
"Census_OSVersion",
"OsBuildLab",
"Census_FirmwareManufacturerIdentifier",
"AVProductStatesIdentifier",
"Census_ProcessorModelIdentifier",
"PuaMode",
"IsBeta",
"UacLuaenable",
"Census_IsFlightsDisabled",
"Firewall",
"Platform",
"Census_DeviceFamily",
"ProductName",
"AutoSampleOptIn",
"HasTpm",
"Census_InternalPrimaryDisplayResolutionHorizontal",
"Census_InternalPrimaryDisplayResolutionVertical"]


def remove_cols(cols_to_remove, cols):
    for i in cols_to_remove:
        cols.remove(i)
    return cols

cols = x_train.columns
final_cols = remove_cols(cols_to_remove, list(cols))
x_train = pd.DataFrame(x_train[final_cols])
x_train.drop(["Census_InternalPrimaryDisplayResolutionHorizontal",
"Census_InternalPrimaryDisplayResolutionVertical"], axis=1, inplace=True)

x_train.SmartScreen = x_train["SmartScreen"].astype('category')
######## random forest implementation

path = 'D:/Document/10 DAAN 881 - Decision Making/Project/data/'
x_train = pd.read_pickle(path + '/x_train_cleaned_for_week5.pkl')
y_train = pd.read_pickle(path + '/y_train_cleaned_for_week5.pkl')
x_train.info()

X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2)

rand_int = np.random.randint(0, x_train.shape[0]*0.8, 2000000)
sample_x = pd.DataFrame(X_train.iloc[rand_int])
sample_y = pd.DataFrame(Y_train.iloc[rand_int])

sample_x_cat = pd.DataFrame(sample_x.select_dtypes('category'))
rand_int_test = np.random.randint(0, X_test.shape[0], 40000)
test_x = pd.DataFrame(X_test.iloc[rand_int_test])
test_y = pd.DataFrame(Y_test.iloc[rand_int_test])

for col in sample_x_cat.columns:
    sample_x[col] = sample_x[col].cat.codes
    test_x[col] = test_x[col].cat.codes


# Creating a bar plot

# grid cv random forest # yes
param_grid = {
    'bootstrap': [True],
    'n_estimators': [2000]
}

rf = RandomForestRegressor()
grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,
                          cv = 2, n_jobs = -1, verbose = 2)

y_values = sample_y.values.ravel()

grid_search.fit(sample_x, y_values)
# grid_search.best_params_
best_grid = grid_search.best_estimator_
best_grid.get_params()
feature_imp = pd.Series(best_grid.feature_importances_,
                        index=sample_x.columns).sort_values(ascending=False)

y_pred = best_grid.predict(test_x)

#Import scikit-learn metrics module for accuracy calculation

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(test_y.values, np.round(y_pred, 0).astype(int)))

def evaluate(best_grid, test_x, test_y):
    y_pred = best_grid.predict(test_x)
    acc = metrics.accuracy_score(test_y.values, np.round(y_pred, 0).astype(int))
    print("Accuracy: ", acc)
    return y_pred, acc

# Confusion matrix


rf = RandomForestClassifier(n_estimators=2000, verbose=1, min_samples_split=10,
                            min_samples_leaf=10, bootstrap=True, n_jobs=-1)
rf.fit(sample_x,sample_y)

feature_imp = pd.Series(rf.feature_importances_,
                        index=sample_x.columns).sort_values(ascending=False)

y_pred, acc = evaluate(rf, test_x, test_y)
y_pred = pd.DataFrame(y_pred)
rf.feature_importances_
pd.DataFrame(feature_imp).to_csv(path + "/feature_imp.csv")
plot_feature(feature_imp)

# del X_train
# del X_test
# del Y_train
# del Y_test
plot_roc(test_y, y_pred, path+"/week5/roc_sample_2000000_2000trees_10minleaf.png")


cm = confusion_matrix(test_y.values.ravel(), np.round(y_pred.values.ravel(),0))
plot_confusion_matrix(cm, classes = ['No Detection', 'Yes Detection'],
                      save_path=path + "/week5/cm_sample_2000000_2000trees_10minleaf",
                      title = 'Malware Detection Confusion Matrix')

#### boruta test

from boruta import BorutaPy
yR = sample_y.values.ravel()
rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)
feat_selector = BorutaPy(rf, n_estimators=1000, verbose=2, random_state=1)


X_train_array = sample_x.values

feat_selector.fit(X_train_array, yR)
feat_selector.ranking_
feat_selector.support_

feature_imp = pd.Series(feat_selector.ranking_,
                        index=sample_x.columns).sort_values(ascending=True)